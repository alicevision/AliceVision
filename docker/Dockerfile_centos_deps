ARG CUDA_VERSION
ARG CENTOS_VERSION
FROM nvidia/cuda:${CUDA_VERSION}-devel-centos${CENTOS_VERSION}
LABEL maintainer="AliceVision Team alicevision-team@googlegroups.com"

# use CUDA_VERSION to select the image version to use
# see https://hub.docker.com/r/nvidia/cuda/
#
# AV_VERSION=2.2.8.develop
# CUDA_VERSION=10.2
# CENTOS_VERSION=20.04
# docker build \
#    --build-arg CUDA_VERSION=${CUDA_VERSION} \
#    --build-arg CENTOS_VERSION=${CENTOS_VERSION} \
#    --tag alicevision/alicevision-deps:${AV_VERSION}-centos${CENTOS_VERSION}-cuda${CUDA_TAG} \
#     -f Dockerfile_deps .

# OS/Version (FILE): cat /etc/issue.net
# Cuda version (ENV): $CUDA_VERSION

ENV AV_DEV=/opt/AliceVisionDeps_git \
    AV_BUILD=/tmp/AliceVisionDeps_build \
    AV_INSTALL=/opt/AliceVision_install \
    VERBOSE=1 \
    YUM_INSTALL='yum install -y --setopt=tsflags=nodocs'

#
# Install all compilation tools
# - file and openssl are needed for cmake
#
# Workaround to give access to deprecated devtoolset-6 is taken from ASWF container:
# https://github.com/AcademySoftwareFoundation/aswf-docker/blob/master/scripts/common/install_yumpackages.sh#L119
#
# Install packages one by one with yum to ensure that it creates an error if a package is missing.
#
RUN $YUM_INSTALL centos-release-scl-rh && \
    $YUM_INSTALL yum-utils && \
    $YUM_INSTALL python3 && \
    $YUM_INSTALL python3-devel && \
    yum clean all && \
    $YUM_INSTALL devtoolset-10-toolchain devtoolset-10-libatomic-devel --nogpgcheck && \
    $YUM_INSTALL --enablerepo=extras epel-release && \
    $YUM_INSTALL file \
        git \
        wget \
        unzip \
        yasm \
        pkgconfig \
        libtool \
        nasm \
        automake \
        which \
        openssl-devel \
        pcre2-devel

# Install numpy for Python3
RUN pip3 install numpy

# Manually install Bison, as Centos7 does not natively support versions beyond 3.0.4
RUN wget http://ftp.gnu.org/gnu/bison/bison-3.6.tar.gz
RUN tar -zxvf bison-3.6.tar.gz
RUN cd bison-3.6 && ./configure && make && make install


# Okay, change our shell to specifically use our software collections.
# (default was SHELL [ "/bin/sh", "-c" ])
# https://docs.docker.com/engine/reference/builder/#shell
#
# See also `scl` man page for enabling multiple packages if desired:
# https://linux.die.net/man/1/scl
# SHELL [ "/usr/bin/scl", "enable", "devtoolset-10" ]
ENV PATH="/opt/rh/devtoolset-10/root/usr/bin:${PATH}" \
    LD_LIBRARY_PATH="/opt/rh/devtoolset-10/root/usr/lib:/opt/rh/devtoolset-10/root/usr/lib64:/opt/rh/devtoolset-10/root/usr/lib64/dyninst:${LD_LIBRARY_PATH}" \
    MAKE=/opt/rh/devtoolset-10/root/usr/bin/make \
    CMAKE_VERSION=3.26.0

COPY dl/vlfeat_K80L3.SIFT.tree ${AV_INSTALL}/share/aliceVision/
RUN echo "export ALICEVISION_VOCTREE=${AV_INSTALL}/share/aliceVision/vlfeat_K80L3.SIFT.tree" > /etc/profile.d/alicevision.sh

COPY dl/sphereDetection_Mask-RCNN.onnx ${AV_INSTALL}/share/aliceVision/
RUN echo "export ALICEVISION_SPHERE_DETECTION_MODEL=${AV_INSTALL}/share/aliceVision/sphereDetection_Mask-RCNN.onnx" > /etc/profile.d/alicevision.sh

COPY dl/fcn_resnet50.onnx ${AV_INSTALL}/share/aliceVision/
RUN echo "export ALICEVISION_SEMANTIC_SEGMENTATION_MODEL=${AV_INSTALL}/share/aliceVision/fcn_resnet50.onnx" > /etc/profile.d/alicevision.sh

COPY docker/check-cpu.sh ${AV_DEV}/docker/check-cpu.sh
RUN export CPU_CORES=`${AV_DEV}/docker/check-cpu.sh` && echo "Build multithreading number of cores: ${CPU_CORES}"

# Manually install cmake
WORKDIR /opt
COPY dl/cmake-${CMAKE_VERSION}.tar.gz /tmp
RUN tar zxf /tmp/cmake-${CMAKE_VERSION}.tar.gz && \
    rm /tmp/cmake-${CMAKE_VERSION}.tar.gz && \
    cd cmake-${CMAKE_VERSION} && \
    ./bootstrap --parallel=${CPU_CORES} --prefix=/usr/local  -- -DCMAKE_BUILD_TYPE:STRING=Release -DCMAKE_USE_OPENSSL:BOOL=ON && \
    make -j ${CPU_CORES} && \
    make install

COPY CMakeLists.txt ${AV_DEV}/
COPY src/cmake/Dependencies.cmake ${AV_DEV}/src/cmake/

COPY dl/deps ${AV_BUILD}/external/download/

WORKDIR "${AV_BUILD}"
RUN cmake "${AV_DEV}" \
     -DCMAKE_BUILD_TYPE=Release \
     -DALICEVISION_BUILD_DEPENDENCIES:BOOL=ON \
     -DAV_BUILD_ALICEVISION:BOOL=OFF \
     -DCMAKE_INSTALL_PREFIX="${AV_INSTALL}"

# Symlink lib64 to lib as qtOIIO expects to find OIIO in lib64
RUN mkdir -p "${AV_INSTALL}/lib" && \
    ln -s lib "${AV_INSTALL}/lib64"

RUN test -e /usr/local/cuda/lib64/libcublas.so || ln -s /usr/lib64/libcublas.so /usr/local/cuda/lib64/libcublas.so

# RUN make -j ${CPU_CORES} onnxruntime
# RUN make -j ${CPU_CORES} pcl
# RUN make -j ${CPU_CORES} turbojpeg
# RUN make -j ${CPU_CORES} boost
# RUN make -j ${CPU_CORES} openexr
# RUN make -j ${CPU_CORES} tbb
# RUN make -j ${CPU_CORES} assimp
# RUN make -j ${CPU_CORES} geogram
# RUN make -j ${CPU_CORES} eigen
# RUN make -j ${CPU_CORES} opengv
# RUN make -j ${CPU_CORES} lapack
# RUN make -j ${CPU_CORES} suitesparse
# RUN make -j ${CPU_CORES} ceres
# RUN make -j ${CPU_CORES} tiff
# RUN make -j ${CPU_CORES} png
# RUN make -j ${CPU_CORES} libraw
# RUN make -j ${CPU_CORES} boost
# RUN make -j ${CPU_CORES} openimageio
# RUN make -j ${CPU_CORES} alembic
# RUN make -j ${CPU_CORES} ffmpeg
# RUN make -j ${CPU_CORES} opencv
# RUN make -j ${CPU_CORES} expat
# RUN make -j ${CPU_CORES} SWIG
# RUN make -j ${CPU_CORES} cctag
# RUN make -j ${CPU_CORES} popsift

RUN cmake --build . -j ${CPU_CORES} && \
    mv "${AV_INSTALL}/bin" "${AV_INSTALL}/bin-deps" && \
    rm -rf "${AV_BUILD}"
